{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "LSTMTesting.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyP7TwosTjZYBm0dyxqoTbpu",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/WilliamAshbee/minigan-catalyst/blob/master/MoreTesting.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q8AVgTkbwGD6"
      },
      "source": [
        "#https://github.com/bhpfelix/PyTorch-Time-Series-Classification-Benchmarks/blob/master/MaterialRecognitionModels.ipynb\r\n",
        "import shutil, os, csv, itertools, glob\r\n",
        "\r\n",
        "import math\r\n",
        "import numpy as np\r\n",
        "import torch\r\n",
        "import torch.nn as nn\r\n",
        "import torch.nn.functional as F\r\n",
        "from torch.autograd import Variable\r\n",
        "from torch.utils.data import Dataset, DataLoader\r\n",
        "import torch.optim as optim\r\n",
        "\r\n",
        "from sklearn.metrics import confusion_matrix\r\n",
        "\r\n",
        "import pandas as pd\r\n",
        "import pickle as pk\r\n",
        "\r\n",
        "cuda = torch.cuda.is_available()\r\n"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tRq9xB1nwKgp"
      },
      "source": [
        "## Multilayer LSTM based classifier taking in 200 dimensional fixed time series inputs\r\n",
        "class LSTMClassifier(nn.Module):\r\n",
        "\r\n",
        "    def __init__(self, in_dim, hidden_dim, num_layers, dropout, bidirectional, num_classes, batch_size):\r\n",
        "        super(LSTMClassifier, self).__init__()\r\n",
        "        self.arch = 'lstm'\r\n",
        "        self.hidden_dim = hidden_dim\r\n",
        "        self.batch_size = batch_size\r\n",
        "        self.num_dir = 2 if bidirectional else 1\r\n",
        "        self.num_layers = num_layers\r\n",
        "        self.h0 = None\r\n",
        "        self.c0 = None\r\n",
        "\r\n",
        "        self.lstm = nn.LSTM(\r\n",
        "                input_size=in_dim,\r\n",
        "                hidden_size=hidden_dim,\r\n",
        "                num_layers=num_layers,\r\n",
        "                dropout=dropout,\r\n",
        "                bidirectional=bidirectional\r\n",
        "            )\r\n",
        "\r\n",
        "        self.hidden2label = nn.Sequential(\r\n",
        "            nn.Linear(hidden_dim*self.num_dir, hidden_dim),\r\n",
        "            nn.ReLU(True),\r\n",
        "            nn.Dropout(),\r\n",
        "            nn.Linear(hidden_dim, hidden_dim),\r\n",
        "            nn.ReLU(True),\r\n",
        "            nn.Dropout(),\r\n",
        "            nn.Linear(hidden_dim, num_classes),\r\n",
        "            nn.Sigmoid()\r\n",
        "        )\r\n",
        "\r\n",
        "        self.hidden = self.init_hidden()\r\n",
        "\r\n",
        "    def setH0(self, h0):\r\n",
        "      self.h0 = h0\r\n",
        "\r\n",
        "    def get_hidden(self):\r\n",
        "      return self.init_hidden(self.h0)\r\n",
        "    \r\n",
        "    def init_hidden(self, h0 = None):\r\n",
        "        if h0 is None:\r\n",
        "          if cuda:\r\n",
        "              h0 = Variable(torch.zeros(self.num_layers*self.num_dir, self.batch_size, self.hidden_dim).cuda())\r\n",
        "              c0 = Variable(torch.zeros(self.num_layers*self.num_dir, self.batch_size, self.hidden_dim).cuda())\r\n",
        "              self.h0 = h0\r\n",
        "              self.c0 = c0\r\n",
        "          else:\r\n",
        "              h0 = Variable(torch.zeros(self.num_layers*self.num_dir, self.batch_size, self.hidden_dim))\r\n",
        "              c0 = Variable(torch.zeros(self.num_layers*self.num_dir, self.batch_size, self.hidden_dim))\r\n",
        "              self.h0 = h0\r\n",
        "              self.c0 = c0\r\n",
        " \r\n",
        "        else:\r\n",
        "          if cuda:\r\n",
        "              self.h0 = h0.cuda()\r\n",
        "              c0 = Variable(torch.zeros(self.num_layers*self.num_dir, self.batch_size, self.hidden_dim).cuda())\r\n",
        "              self.c0 = c0\r\n",
        "          else:\r\n",
        "              self.h0 = h0\r\n",
        "              c0 = Variable(torch.zeros(self.num_layers*self.num_dir, self.batch_size, self.hidden_dim))\r\n",
        "              self.c0 = c0\r\n",
        "        \r\n",
        "        return (self.h0, self.c0)\r\n",
        "\r\n",
        "    def forward(self, x): # x is (batch_size, 1, 200), permute to (200, batch_size, 1)\r\n",
        "        x = x.permute(2, 0, 1)\r\n",
        "        # See: https://discuss.pytorch.org/t/solved-why-we-need-to-detach-variable-which-contains-hidden-representation/1426/2\r\n",
        "        if self.h0 is None:\r\n",
        "          self.init_hidden()\r\n",
        "        lstm_out, (h, c) = self.lstm(x, self.get_hidden())\r\n",
        "        y  = self.hidden2label(lstm_out[-1])\r\n",
        "        #self.h0 = None\r\n",
        "        return y\r\n",
        "    \r\n",
        "    def setBatchSize(self, batch_size = 1):\r\n",
        "        self.batch_size = batch_size\r\n"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xqG7ptZwwK_5"
      },
      "source": [
        "def get_models(): # tuples of (batch_size, model)\r\n",
        "    return [\r\n",
        "         LSTMClassifier(\r\n",
        "            in_dim=2,\r\n",
        "            hidden_dim=512,\r\n",
        "            num_layers=3,\r\n",
        "            dropout=0.8,\r\n",
        "            bidirectional=True,\r\n",
        "            num_classes=1,#bce loss for discriminator\r\n",
        "            batch_size=64\r\n",
        "        )\r\n",
        "    ]\r\n"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9WHT5frSfmqz"
      },
      "source": [
        "#https://github.com/bhpfelix/PyTorch-Time-Series-Classification-Benchmarks/blob/master/MaterialRecognitionModels.ipynb"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6f5KB0Duh9W5"
      },
      "source": [
        "import torch\r\n",
        "import torch.nn as nn\r\n",
        "from torch.hub import load_state_dict_from_url\r\n",
        "\r\n",
        "\r\n",
        "__all__ = ['ResNet', 'resnet18', 'resnet34', 'resnet50', 'resnet101',\r\n",
        "           'resnet152', 'resnext50_32x4d', 'resnext101_32x8d',\r\n",
        "           'wide_resnet50_2', 'wide_resnet101_2']\r\n",
        "\r\n",
        "\r\n",
        "model_urls = {\r\n",
        "    'resnet18': 'https://download.pytorch.org/models/resnet18-5c106cde.pth',\r\n",
        "    'resnet34': 'https://download.pytorch.org/models/resnet34-333f7ec4.pth',\r\n",
        "    'resnet50': 'https://download.pytorch.org/models/resnet50-19c8e357.pth',\r\n",
        "    'resnet101': 'https://download.pytorch.org/models/resnet101-5d3b4d8f.pth',\r\n",
        "    'resnet152': 'https://download.pytorch.org/models/resnet152-b121ed2d.pth',\r\n",
        "    'resnext50_32x4d': 'https://download.pytorch.org/models/resnext50_32x4d-7cdf4587.pth',\r\n",
        "    'resnext101_32x8d': 'https://download.pytorch.org/models/resnext101_32x8d-8ba56ff5.pth',\r\n",
        "    'wide_resnet50_2': 'https://download.pytorch.org/models/wide_resnet50_2-95faca4d.pth',\r\n",
        "    'wide_resnet101_2': 'https://download.pytorch.org/models/wide_resnet101_2-32ee1156.pth',\r\n",
        "}\r\n",
        "\r\n",
        "\r\n",
        "def conv3x3(in_planes, out_planes, stride=1, groups=1, dilation=1):\r\n",
        "    \"\"\"3x3 convolution with padding\"\"\"\r\n",
        "    return nn.Conv2d(in_planes, out_planes, kernel_size=3, stride=stride,\r\n",
        "                     padding=dilation, groups=groups, bias=False, dilation=dilation)\r\n",
        "\r\n",
        "\r\n",
        "def conv1x1(in_planes, out_planes, stride=1):\r\n",
        "    \"\"\"1x1 convolution\"\"\"\r\n",
        "    return nn.Conv2d(in_planes, out_planes, kernel_size=1, stride=stride, bias=False)\r\n",
        "\r\n",
        "\r\n",
        "class BasicBlock(nn.Module):\r\n",
        "    expansion = 1\r\n",
        "\r\n",
        "    def __init__(self, inplanes, planes, stride=1, downsample=None, groups=1,\r\n",
        "                 base_width=64, dilation=1, norm_layer=None):\r\n",
        "        super(BasicBlock, self).__init__()\r\n",
        "        if norm_layer is None:\r\n",
        "            norm_layer = nn.BatchNorm2d\r\n",
        "        if groups != 1 or base_width != 64:\r\n",
        "            raise ValueError('BasicBlock only supports groups=1 and base_width=64')\r\n",
        "        if dilation > 1:\r\n",
        "            raise NotImplementedError(\"Dilation > 1 not supported in BasicBlock\")\r\n",
        "        # Both self.conv1 and self.downsample layers downsample the input when stride != 1\r\n",
        "        self.conv1 = conv3x3(inplanes, planes, stride)\r\n",
        "        self.bn1 = norm_layer(planes)\r\n",
        "        self.relu = nn.ReLU(inplace=False)\r\n",
        "        self.conv2 = conv3x3(planes, planes)\r\n",
        "        self.bn2 = norm_layer(planes)\r\n",
        "        self.downsample = downsample\r\n",
        "        self.stride = stride\r\n",
        "\r\n",
        "    def forward(self, x):\r\n",
        "        identity = x\r\n",
        "\r\n",
        "        out = self.conv1(x)\r\n",
        "        out = self.bn1(out)\r\n",
        "        out = self.relu(out)\r\n",
        "\r\n",
        "        out = self.conv2(out)\r\n",
        "        out = self.bn2(out)\r\n",
        "\r\n",
        "        if self.downsample is not None:\r\n",
        "            identity = self.downsample(x)\r\n",
        "\r\n",
        "        out += identity\r\n",
        "        out = self.relu(out)\r\n",
        "\r\n",
        "        return out\r\n",
        "\r\n",
        "\r\n",
        "class Bottleneck(nn.Module):\r\n",
        "    # Bottleneck in torchvision places the stride for downsampling at 3x3 convolution(self.conv2)\r\n",
        "    # while original implementation places the stride at the first 1x1 convolution(self.conv1)\r\n",
        "    # according to \"Deep residual learning for image recognition\"https://arxiv.org/abs/1512.03385.\r\n",
        "    # This variant is also known as ResNet V1.5 and improves accuracy according to\r\n",
        "    # https://ngc.nvidia.com/catalog/model-scripts/nvidia:resnet_50_v1_5_for_pytorch.\r\n",
        "\r\n",
        "    expansion = 4\r\n",
        "\r\n",
        "    def __init__(self, inplanes, planes, stride=1, downsample=None, groups=1,\r\n",
        "                 base_width=64, dilation=1, norm_layer=None):\r\n",
        "        super(Bottleneck, self).__init__()\r\n",
        "        if norm_layer is None:\r\n",
        "            norm_layer = nn.BatchNorm2d\r\n",
        "        width = int(planes * (base_width / 64.)) * groups\r\n",
        "        # Both self.conv2 and self.downsample layers downsample the input when stride != 1\r\n",
        "        self.conv1 = conv1x1(inplanes, width)\r\n",
        "        self.bn1 = norm_layer(width)\r\n",
        "        self.conv2 = conv3x3(width, width, stride, groups, dilation)\r\n",
        "        self.bn2 = norm_layer(width)\r\n",
        "        self.conv3 = conv1x1(width, planes * self.expansion)\r\n",
        "        self.bn3 = norm_layer(planes * self.expansion)\r\n",
        "        self.relu = nn.ReLU(inplace=False)\r\n",
        "        self.downsample = downsample\r\n",
        "        self.stride = stride\r\n",
        "\r\n",
        "    def forward(self, x):\r\n",
        "        identity = x\r\n",
        "\r\n",
        "        out = self.conv1(x)\r\n",
        "        out = self.bn1(out)\r\n",
        "        out = self.relu(out)\r\n",
        "\r\n",
        "        out = self.conv2(out)\r\n",
        "        out = self.bn2(out)\r\n",
        "        out = self.relu(out)\r\n",
        "\r\n",
        "        out = self.conv3(out)\r\n",
        "        out = self.bn3(out)\r\n",
        "\r\n",
        "        if self.downsample is not None:\r\n",
        "            identity = self.downsample(x)\r\n",
        "\r\n",
        "        out += identity\r\n",
        "        out = self.relu(out)\r\n",
        "\r\n",
        "        return out\r\n",
        "\r\n",
        "\r\n",
        "class ResNet(nn.Module):\r\n",
        "\r\n",
        "    def __init__(self, block, layers, num_classes=2000, zero_init_residual=False,\r\n",
        "                 groups=1, width_per_group=64, replace_stride_with_dilation=None,\r\n",
        "                 norm_layer=None):\r\n",
        "        super(ResNet, self).__init__()\r\n",
        "        if norm_layer is None:\r\n",
        "            norm_layer = nn.BatchNorm2d\r\n",
        "        self._norm_layer = norm_layer\r\n",
        "\r\n",
        "        self.inplanes = 64\r\n",
        "        self.dilation = 1\r\n",
        "        if replace_stride_with_dilation is None:\r\n",
        "            # each element in the tuple indicates if we should replace\r\n",
        "            # the 2x2 stride with a dilated convolution instead\r\n",
        "            replace_stride_with_dilation = [False, False, False]\r\n",
        "        if len(replace_stride_with_dilation) != 3:\r\n",
        "            raise ValueError(\"replace_stride_with_dilation should be None \"\r\n",
        "                             \"or a 3-element tuple, got {}\".format(replace_stride_with_dilation))\r\n",
        "        self.groups = groups\r\n",
        "        self.base_width = width_per_group\r\n",
        "        self.conv1 = nn.Conv2d(5, self.inplanes, kernel_size=7, stride=2, padding=3,\r\n",
        "                               bias=False)\r\n",
        "        self.bn1 = norm_layer(self.inplanes)\r\n",
        "        self.relu = nn.ReLU(inplace=False)\r\n",
        "        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\r\n",
        "        self.layer1 = self._make_layer(block, 64, layers[0])\r\n",
        "        self.layer2 = self._make_layer(block, 128, layers[1], stride=2,\r\n",
        "                                       dilate=replace_stride_with_dilation[0])\r\n",
        "        self.layer3 = self._make_layer(block, 256, layers[2], stride=2,\r\n",
        "                                       dilate=replace_stride_with_dilation[1])\r\n",
        "        self.layer4 = self._make_layer(block, 512, layers[3], stride=2,\r\n",
        "                                       dilate=replace_stride_with_dilation[2])\r\n",
        "        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))\r\n",
        "        self.fc = nn.Linear(512 * block.expansion, num_classes)\r\n",
        "\r\n",
        "        for m in self.modules():\r\n",
        "            if isinstance(m, nn.Conv2d):\r\n",
        "                nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\r\n",
        "            elif isinstance(m, (nn.BatchNorm2d, nn.GroupNorm)):\r\n",
        "                nn.init.constant_(m.weight, 1)\r\n",
        "                nn.init.constant_(m.bias, 0)\r\n",
        "\r\n",
        "        # Zero-initialize the last BN in each residual branch,\r\n",
        "        # so that the residual branch starts with zeros, and each residual block behaves like an identity.\r\n",
        "        # This improves the model by 0.2~0.3% according to https://arxiv.org/abs/1706.02677\r\n",
        "        if zero_init_residual:\r\n",
        "            for m in self.modules():\r\n",
        "                if isinstance(m, Bottleneck):\r\n",
        "                    nn.init.constant_(m.bn3.weight, 0)\r\n",
        "                elif isinstance(m, BasicBlock):\r\n",
        "                    nn.init.constant_(m.bn2.weight, 0)\r\n",
        "\r\n",
        "    def _make_layer(self, block, planes, blocks, stride=1, dilate=False):\r\n",
        "        norm_layer = self._norm_layer\r\n",
        "        downsample = None\r\n",
        "        previous_dilation = self.dilation\r\n",
        "        if dilate:\r\n",
        "            self.dilation *= stride\r\n",
        "            stride = 1\r\n",
        "        if stride != 1 or self.inplanes != planes * block.expansion:\r\n",
        "            downsample = nn.Sequential(\r\n",
        "                conv1x1(self.inplanes, planes * block.expansion, stride),\r\n",
        "                norm_layer(planes * block.expansion),\r\n",
        "            )\r\n",
        "\r\n",
        "        layers = []\r\n",
        "        layers.append(block(self.inplanes, planes, stride, downsample, self.groups,\r\n",
        "                            self.base_width, previous_dilation, norm_layer))\r\n",
        "        self.inplanes = planes * block.expansion\r\n",
        "        for _ in range(1, blocks):\r\n",
        "            layers.append(block(self.inplanes, planes, groups=self.groups,\r\n",
        "                                base_width=self.base_width, dilation=self.dilation,\r\n",
        "                                norm_layer=norm_layer))\r\n",
        "\r\n",
        "        return nn.Sequential(*layers)\r\n",
        "\r\n",
        "    def _forward_impl(self, x):\r\n",
        "        # See note [TorchScript super()]\r\n",
        "        x = self.conv1(x)\r\n",
        "        x = self.bn1(x)\r\n",
        "        x = self.relu(x)\r\n",
        "        x = self.maxpool(x)\r\n",
        "\r\n",
        "        x = self.layer1(x)\r\n",
        "        x = self.layer2(x)\r\n",
        "        x = self.layer3(x)\r\n",
        "        x = self.layer4(x)\r\n",
        "\r\n",
        "        x = self.avgpool(x)\r\n",
        "        x = torch.flatten(x, 1)\r\n",
        "        x = self.fc(x)\r\n",
        "\r\n",
        "        return x\r\n",
        "\r\n",
        "    def forward(self, x):\r\n",
        "        return self._forward_impl(x)\r\n",
        "\r\n",
        "\r\n",
        "def _resnet(arch, block, layers, pretrained, progress, **kwargs):\r\n",
        "    model = ResNet(block, layers, **kwargs)\r\n",
        "    if pretrained:\r\n",
        "        state_dict = load_state_dict_from_url(model_urls[arch],\r\n",
        "                                              progress=progress)\r\n",
        "        model.load_state_dict(state_dict)\r\n",
        "    return model\r\n",
        "\r\n",
        "def resnet18(pretrained=False, progress=True, **kwargs):\r\n",
        "    \"\"\"ResNet-18 model from\r\n",
        "    `\"Deep Residual Learning for Image Recognition\" <https://arxiv.org/pdf/1512.03385.pdf>`_\r\n",
        "\r\n",
        "    Args:\r\n",
        "        pretrained (bool): If True, returns a model pre-trained on ImageNet\r\n",
        "        progress (bool): If True, displays a progress bar of the download to stderr\r\n",
        "    \"\"\"\r\n",
        "    return _resnet('resnet18', BasicBlock, [2, 2, 2, 2], pretrained, progress,\r\n",
        "                   **kwargs)\r\n",
        "\r\n",
        "def resnext101_32x8d(pretrained=False, progress=True, **kwargs):\r\n",
        "    \"\"\"ResNeXt-101 32x8d model from\r\n",
        "    Aggregated Residual Transformation for Deep Neural Networks\" <https://arxiv.org/pdf/1611.05431.pdf>\r\n",
        "\r\n",
        "    Args:\r\n",
        "        pretrained (bool): If True, returns a model pre-trained on ImageNet\r\n",
        "        progress (bool): If True, displays a progress bar of the download to stderr\r\n",
        "    \"\"\"\r\n",
        "    kwargs['groups'] = 32\r\n",
        "    kwargs['width_per_group'] = 8\r\n",
        "    return _resnet('resnext101_32x8d', Bottleneck, [3, 4, 23, 3],\r\n",
        "                   pretrained, progress, **kwargs)"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CBec9YDepIOK"
      },
      "source": [
        "G =  resnet18(pretrained=False, progress=True).cuda()\r\n",
        "D = get_models()[0].cuda() \r\n",
        "D_optimizer = optim.Adam(D.parameters(), lr=.0001, betas=(0.5, 0.999))\r\n",
        "G_optimizer = optim.Adam(G.parameters(), lr=.0001, betas=(0.5, 0.999))\r\n",
        "a = torch.ones(64, 5, 32, 32).float().cuda()\r\n",
        "og = G(a)\r\n",
        "ogr = og.reshape(-1,2,1000)\r\n",
        "od = D(ogr)\r\n",
        "gtd = torch.ones(64,1).cuda()\r\n",
        "loss = nn.BCELoss()\r\n",
        "lossout = loss(od,gtd)\r\n",
        "lossout.backward()\r\n",
        "G_optimizer.step()"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hkZ6tSE-kC6q",
        "outputId": "d1c54ea1-4973-4c9b-f951-79d42d980dc5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "x = torch.ones(2,5, 32, 32)\r\n",
        "model = resnet18()\r\n",
        "model(x).shape"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([2, 2000])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "arZ9cNiClQdg"
      },
      "source": [
        "import torchvision\r\n",
        "fa = torchvision.models.resnet18(pretrained=True)\r\n"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xjOhEKIJsiMf",
        "outputId": "85082a84-cabf-48cc-ba23-5333e54dda9b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "fa"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ResNet(\n",
              "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
              "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  (relu): ReLU(inplace=True)\n",
              "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
              "  (layer1): Sequential(\n",
              "    (0): BasicBlock(\n",
              "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (1): BasicBlock(\n",
              "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "  )\n",
              "  (layer2): Sequential(\n",
              "    (0): BasicBlock(\n",
              "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (downsample): Sequential(\n",
              "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (1): BasicBlock(\n",
              "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "  )\n",
              "  (layer3): Sequential(\n",
              "    (0): BasicBlock(\n",
              "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (downsample): Sequential(\n",
              "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (1): BasicBlock(\n",
              "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "  )\n",
              "  (layer4): Sequential(\n",
              "    (0): BasicBlock(\n",
              "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (downsample): Sequential(\n",
              "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (1): BasicBlock(\n",
              "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "  )\n",
              "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
              "  (fc): Linear(in_features=512, out_features=1000, bias=True)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JaLI5JZKvLtN",
        "outputId": "869adea9-bdce-4b70-dd3c-a4462b0e6139",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "fa.named_children()"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<generator object Module.named_children at 0x7fd8544af570>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RZXFRJayvOsb"
      },
      "source": [
        "fa.fc = nn.Sequential()"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w1LXKUNbwZjZ"
      },
      "source": [
        "x = torch.ones(2,3, 32, 32)\r\n",
        "out = fa(x)"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Oj6wr_sqwijF",
        "outputId": "a6f35c46-3052-40da-86d4-8223240f7b0c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "out.shape"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([2, 512])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8GiOe-46wqcz"
      },
      "source": [
        "h = out"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FQolkV_vHlfM"
      },
      "source": [
        "D = get_models()[0]"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PUzc9QfgINDu"
      },
      "source": [
        "hid = D.init_hidden(h)"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K4GJp_0yISF6",
        "outputId": "e48e49de-bbc4-4656-d723-0360f730a3c2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "hid[0].shape"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([2, 512])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oCRB68iTISbu"
      },
      "source": [
        "temp = torch.zeros(6,128,512)\r\n",
        "            "
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "awaUdEoBTXgR"
      },
      "source": [
        "abc = torch.randn(128,512)"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v-iLGdbhUamR",
        "outputId": "5e1e0297-9d8f-4a4d-cc9a-2129a0f126f9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "import numpy as np\r\n",
        "b = torch.randn(128,512)\r\n",
        "\r\n",
        "b = b.cpu().numpy()\r\n",
        "a = torch.from_numpy(np.tile(b,(6,1,1)))\r\n",
        "a.shape"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([6, 128, 512])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2bsf5QdgY6wV"
      },
      "source": [
        ""
      ],
      "execution_count": 22,
      "outputs": []
    }
  ]
}