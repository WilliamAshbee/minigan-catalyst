{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "LSTMTesting.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPj7/7gzplsZEEnu3KlpnCO",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/WilliamAshbee/minigan-catalyst/blob/master/MoreTesting.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q8AVgTkbwGD6"
      },
      "source": [
        "#https://github.com/bhpfelix/PyTorch-Time-Series-Classification-Benchmarks/blob/master/MaterialRecognitionModels.ipynb\r\n",
        "import shutil, os, csv, itertools, glob\r\n",
        "\r\n",
        "import math\r\n",
        "import numpy as np\r\n",
        "import torch\r\n",
        "import torch.nn as nn\r\n",
        "import torch.nn.functional as F\r\n",
        "from torch.autograd import Variable\r\n",
        "from torch.utils.data import Dataset, DataLoader\r\n",
        "import torch.optim as optim\r\n",
        "\r\n",
        "from sklearn.metrics import confusion_matrix\r\n",
        "\r\n",
        "import pandas as pd\r\n",
        "import pickle as pk\r\n",
        "\r\n",
        "cuda = torch.cuda.is_available()\r\n"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tRq9xB1nwKgp"
      },
      "source": [
        "## Multilayer LSTM based classifier taking in 200 dimensional fixed time series inputs\r\n",
        "class LSTMClassifier(nn.Module):\r\n",
        "\r\n",
        "    def __init__(self, in_dim, hidden_dim, num_layers, dropout, bidirectional, num_classes, batch_size):\r\n",
        "        super(LSTMClassifier, self).__init__()\r\n",
        "        self.arch = 'lstm'\r\n",
        "        self.hidden_dim = hidden_dim\r\n",
        "        self.batch_size = batch_size\r\n",
        "        self.num_dir = 2 if bidirectional else 1\r\n",
        "        self.num_layers = num_layers\r\n",
        "        self.h0 = None\r\n",
        "        self.c0 = None\r\n",
        "\r\n",
        "        self.lstm = nn.LSTM(\r\n",
        "                input_size=in_dim,\r\n",
        "                hidden_size=hidden_dim,\r\n",
        "                num_layers=num_layers,\r\n",
        "                dropout=dropout,\r\n",
        "                bidirectional=bidirectional\r\n",
        "            )\r\n",
        "\r\n",
        "        self.hidden2label = nn.Sequential(\r\n",
        "            nn.Linear(hidden_dim*self.num_dir, hidden_dim),\r\n",
        "            nn.ReLU(True),\r\n",
        "            nn.Dropout(),\r\n",
        "            nn.Linear(hidden_dim, hidden_dim),\r\n",
        "            nn.ReLU(True),\r\n",
        "            nn.Dropout(),\r\n",
        "            nn.Linear(hidden_dim, num_classes),\r\n",
        "            nn.Sigmoid()\r\n",
        "        )\r\n",
        "\r\n",
        "        self.hidden = self.init_hidden()\r\n",
        "\r\n",
        "    def setH0(self, h0):\r\n",
        "      self.h0 = h0\r\n",
        "\r\n",
        "    def get_hidden(self):\r\n",
        "      return self.init_hidden(self.h0)\r\n",
        "    \r\n",
        "    def init_hidden(self, h0 = None):\r\n",
        "        if h0 is None:\r\n",
        "          if cuda:\r\n",
        "              h0 = Variable(torch.zeros(self.num_layers*self.num_dir, self.batch_size, self.hidden_dim).cuda())\r\n",
        "              c0 = Variable(torch.zeros(self.num_layers*self.num_dir, self.batch_size, self.hidden_dim).cuda())\r\n",
        "              self.h0 = h0\r\n",
        "              self.c0 = c0\r\n",
        "          else:\r\n",
        "              h0 = Variable(torch.zeros(self.num_layers*self.num_dir, self.batch_size, self.hidden_dim))\r\n",
        "              c0 = Variable(torch.zeros(self.num_layers*self.num_dir, self.batch_size, self.hidden_dim))\r\n",
        "              self.h0 = h0\r\n",
        "              self.c0 = c0\r\n",
        " \r\n",
        "        else:\r\n",
        "          if cuda:\r\n",
        "              self.h0 = h0.cuda()\r\n",
        "              c0 = Variable(torch.zeros(self.num_layers*self.num_dir, self.batch_size, self.hidden_dim).cuda())\r\n",
        "              self.c0 = c0\r\n",
        "          else:\r\n",
        "              self.h0 = h0\r\n",
        "              c0 = Variable(torch.zeros(self.num_layers*self.num_dir, self.batch_size, self.hidden_dim))\r\n",
        "              self.c0 = c0\r\n",
        "        \r\n",
        "        return (self.h0, self.c0)\r\n",
        "\r\n",
        "    def forward(self, x): # x is (batch_size, 1, 200), permute to (200, batch_size, 1)\r\n",
        "        x = x.permute(2, 0, 1)\r\n",
        "        # See: https://discuss.pytorch.org/t/solved-why-we-need-to-detach-variable-which-contains-hidden-representation/1426/2\r\n",
        "        if self.h0 is None:\r\n",
        "          self.init_hidden()\r\n",
        "        lstm_out, (h, c) = self.lstm(x, self.get_hidden())\r\n",
        "        y  = self.hidden2label(lstm_out[-1])\r\n",
        "        #self.h0 = None\r\n",
        "        return y\r\n",
        "    \r\n",
        "    def setBatchSize(self, batch_size = 1):\r\n",
        "        self.batch_size = batch_size\r\n"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xqG7ptZwwK_5"
      },
      "source": [
        "def get_models(): # tuples of (batch_size, model)\r\n",
        "    return [\r\n",
        "         LSTMClassifier(\r\n",
        "            in_dim=2,\r\n",
        "            hidden_dim=512,\r\n",
        "            num_layers=3,\r\n",
        "            dropout=0.8,\r\n",
        "            bidirectional=True,\r\n",
        "            num_classes=1,#bce loss for discriminator\r\n",
        "            batch_size=256\r\n",
        "        )\r\n",
        "    ]\r\n"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9WHT5frSfmqz"
      },
      "source": [
        "#https://github.com/bhpfelix/PyTorch-Time-Series-Classification-Benchmarks/blob/master/MaterialRecognitionModels.ipynb"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6f5KB0Duh9W5"
      },
      "source": [
        "import torch\r\n",
        "import torch.nn as nn\r\n",
        "from torch.hub import load_state_dict_from_url\r\n",
        "\r\n",
        "\r\n",
        "__all__ = ['ResNet', 'resnet18', 'resnet34', 'resnet50', 'resnet101',\r\n",
        "           'resnet152', 'resnext50_32x4d', 'resnext101_32x8d',\r\n",
        "           'wide_resnet50_2', 'wide_resnet101_2']\r\n",
        "\r\n",
        "\r\n",
        "model_urls = {\r\n",
        "    'resnet18': 'https://download.pytorch.org/models/resnet18-5c106cde.pth',\r\n",
        "    'resnet34': 'https://download.pytorch.org/models/resnet34-333f7ec4.pth',\r\n",
        "    'resnet50': 'https://download.pytorch.org/models/resnet50-19c8e357.pth',\r\n",
        "    'resnet101': 'https://download.pytorch.org/models/resnet101-5d3b4d8f.pth',\r\n",
        "    'resnet152': 'https://download.pytorch.org/models/resnet152-b121ed2d.pth',\r\n",
        "    'resnext50_32x4d': 'https://download.pytorch.org/models/resnext50_32x4d-7cdf4587.pth',\r\n",
        "    'resnext101_32x8d': 'https://download.pytorch.org/models/resnext101_32x8d-8ba56ff5.pth',\r\n",
        "    'wide_resnet50_2': 'https://download.pytorch.org/models/wide_resnet50_2-95faca4d.pth',\r\n",
        "    'wide_resnet101_2': 'https://download.pytorch.org/models/wide_resnet101_2-32ee1156.pth',\r\n",
        "}\r\n",
        "\r\n",
        "\r\n",
        "def conv3x3(in_planes, out_planes, stride=1, groups=1, dilation=1):\r\n",
        "    \"\"\"3x3 convolution with padding\"\"\"\r\n",
        "    return nn.Conv2d(in_planes, out_planes, kernel_size=3, stride=stride,\r\n",
        "                     padding=dilation, groups=groups, bias=False, dilation=dilation)\r\n",
        "\r\n",
        "\r\n",
        "def conv1x1(in_planes, out_planes, stride=1):\r\n",
        "    \"\"\"1x1 convolution\"\"\"\r\n",
        "    return nn.Conv2d(in_planes, out_planes, kernel_size=1, stride=stride, bias=False)\r\n",
        "\r\n",
        "\r\n",
        "class BasicBlock(nn.Module):\r\n",
        "    expansion = 1\r\n",
        "\r\n",
        "    def __init__(self, inplanes, planes, stride=1, downsample=None, groups=1,\r\n",
        "                 base_width=64, dilation=1, norm_layer=None):\r\n",
        "        super(BasicBlock, self).__init__()\r\n",
        "        if norm_layer is None:\r\n",
        "            norm_layer = nn.BatchNorm2d\r\n",
        "        if groups != 1 or base_width != 64:\r\n",
        "            raise ValueError('BasicBlock only supports groups=1 and base_width=64')\r\n",
        "        if dilation > 1:\r\n",
        "            raise NotImplementedError(\"Dilation > 1 not supported in BasicBlock\")\r\n",
        "        # Both self.conv1 and self.downsample layers downsample the input when stride != 1\r\n",
        "        self.conv1 = conv3x3(inplanes, planes, stride)\r\n",
        "        self.bn1 = norm_layer(planes)\r\n",
        "        self.relu = nn.ReLU(inplace=False)\r\n",
        "        self.conv2 = conv3x3(planes, planes)\r\n",
        "        self.bn2 = norm_layer(planes)\r\n",
        "        self.downsample = downsample\r\n",
        "        self.stride = stride\r\n",
        "\r\n",
        "    def forward(self, x):\r\n",
        "        identity = x\r\n",
        "\r\n",
        "        out = self.conv1(x)\r\n",
        "        out = self.bn1(out)\r\n",
        "        out = self.relu(out)\r\n",
        "\r\n",
        "        out = self.conv2(out)\r\n",
        "        out = self.bn2(out)\r\n",
        "\r\n",
        "        if self.downsample is not None:\r\n",
        "            identity = self.downsample(x)\r\n",
        "\r\n",
        "        out += identity\r\n",
        "        out = self.relu(out)\r\n",
        "\r\n",
        "        return out\r\n",
        "\r\n",
        "\r\n",
        "class Bottleneck(nn.Module):\r\n",
        "    # Bottleneck in torchvision places the stride for downsampling at 3x3 convolution(self.conv2)\r\n",
        "    # while original implementation places the stride at the first 1x1 convolution(self.conv1)\r\n",
        "    # according to \"Deep residual learning for image recognition\"https://arxiv.org/abs/1512.03385.\r\n",
        "    # This variant is also known as ResNet V1.5 and improves accuracy according to\r\n",
        "    # https://ngc.nvidia.com/catalog/model-scripts/nvidia:resnet_50_v1_5_for_pytorch.\r\n",
        "\r\n",
        "    expansion = 4\r\n",
        "\r\n",
        "    def __init__(self, inplanes, planes, stride=1, downsample=None, groups=1,\r\n",
        "                 base_width=64, dilation=1, norm_layer=None):\r\n",
        "        super(Bottleneck, self).__init__()\r\n",
        "        if norm_layer is None:\r\n",
        "            norm_layer = nn.BatchNorm2d\r\n",
        "        width = int(planes * (base_width / 64.)) * groups\r\n",
        "        # Both self.conv2 and self.downsample layers downsample the input when stride != 1\r\n",
        "        self.conv1 = conv1x1(inplanes, width)\r\n",
        "        self.bn1 = norm_layer(width)\r\n",
        "        self.conv2 = conv3x3(width, width, stride, groups, dilation)\r\n",
        "        self.bn2 = norm_layer(width)\r\n",
        "        self.conv3 = conv1x1(width, planes * self.expansion)\r\n",
        "        self.bn3 = norm_layer(planes * self.expansion)\r\n",
        "        self.relu = nn.ReLU(inplace=False)\r\n",
        "        self.downsample = downsample\r\n",
        "        self.stride = stride\r\n",
        "\r\n",
        "    def forward(self, x):\r\n",
        "        identity = x\r\n",
        "\r\n",
        "        out = self.conv1(x)\r\n",
        "        out = self.bn1(out)\r\n",
        "        out = self.relu(out)\r\n",
        "\r\n",
        "        out = self.conv2(out)\r\n",
        "        out = self.bn2(out)\r\n",
        "        out = self.relu(out)\r\n",
        "\r\n",
        "        out = self.conv3(out)\r\n",
        "        out = self.bn3(out)\r\n",
        "\r\n",
        "        if self.downsample is not None:\r\n",
        "            identity = self.downsample(x)\r\n",
        "\r\n",
        "        out += identity\r\n",
        "        out = self.relu(out)\r\n",
        "\r\n",
        "        return out\r\n",
        "\r\n",
        "\r\n",
        "class ResNet(nn.Module):\r\n",
        "\r\n",
        "    def __init__(self, block, layers, num_classes=2000, zero_init_residual=False,\r\n",
        "                 groups=1, width_per_group=64, replace_stride_with_dilation=None,\r\n",
        "                 norm_layer=None):\r\n",
        "        super(ResNet, self).__init__()\r\n",
        "        if norm_layer is None:\r\n",
        "            norm_layer = nn.BatchNorm2d\r\n",
        "        self._norm_layer = norm_layer\r\n",
        "\r\n",
        "        self.inplanes = 64\r\n",
        "        self.dilation = 1\r\n",
        "        if replace_stride_with_dilation is None:\r\n",
        "            # each element in the tuple indicates if we should replace\r\n",
        "            # the 2x2 stride with a dilated convolution instead\r\n",
        "            replace_stride_with_dilation = [False, False, False]\r\n",
        "        if len(replace_stride_with_dilation) != 3:\r\n",
        "            raise ValueError(\"replace_stride_with_dilation should be None \"\r\n",
        "                             \"or a 3-element tuple, got {}\".format(replace_stride_with_dilation))\r\n",
        "        self.groups = groups\r\n",
        "        self.base_width = width_per_group\r\n",
        "        self.conv1 = nn.Conv2d(5, self.inplanes, kernel_size=7, stride=2, padding=3,\r\n",
        "                               bias=False)\r\n",
        "        self.bn1 = norm_layer(self.inplanes)\r\n",
        "        self.relu = nn.ReLU(inplace=False)\r\n",
        "        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\r\n",
        "        self.layer1 = self._make_layer(block, 64, layers[0])\r\n",
        "        self.layer2 = self._make_layer(block, 128, layers[1], stride=2,\r\n",
        "                                       dilate=replace_stride_with_dilation[0])\r\n",
        "        self.layer3 = self._make_layer(block, 256, layers[2], stride=2,\r\n",
        "                                       dilate=replace_stride_with_dilation[1])\r\n",
        "        self.layer4 = self._make_layer(block, 512, layers[3], stride=2,\r\n",
        "                                       dilate=replace_stride_with_dilation[2])\r\n",
        "        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))\r\n",
        "        self.fc = nn.Linear(512 * block.expansion, num_classes)\r\n",
        "\r\n",
        "        for m in self.modules():\r\n",
        "            if isinstance(m, nn.Conv2d):\r\n",
        "                nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\r\n",
        "            elif isinstance(m, (nn.BatchNorm2d, nn.GroupNorm)):\r\n",
        "                nn.init.constant_(m.weight, 1)\r\n",
        "                nn.init.constant_(m.bias, 0)\r\n",
        "\r\n",
        "        # Zero-initialize the last BN in each residual branch,\r\n",
        "        # so that the residual branch starts with zeros, and each residual block behaves like an identity.\r\n",
        "        # This improves the model by 0.2~0.3% according to https://arxiv.org/abs/1706.02677\r\n",
        "        if zero_init_residual:\r\n",
        "            for m in self.modules():\r\n",
        "                if isinstance(m, Bottleneck):\r\n",
        "                    nn.init.constant_(m.bn3.weight, 0)\r\n",
        "                elif isinstance(m, BasicBlock):\r\n",
        "                    nn.init.constant_(m.bn2.weight, 0)\r\n",
        "\r\n",
        "    def _make_layer(self, block, planes, blocks, stride=1, dilate=False):\r\n",
        "        norm_layer = self._norm_layer\r\n",
        "        downsample = None\r\n",
        "        previous_dilation = self.dilation\r\n",
        "        if dilate:\r\n",
        "            self.dilation *= stride\r\n",
        "            stride = 1\r\n",
        "        if stride != 1 or self.inplanes != planes * block.expansion:\r\n",
        "            downsample = nn.Sequential(\r\n",
        "                conv1x1(self.inplanes, planes * block.expansion, stride),\r\n",
        "                norm_layer(planes * block.expansion),\r\n",
        "            )\r\n",
        "\r\n",
        "        layers = []\r\n",
        "        layers.append(block(self.inplanes, planes, stride, downsample, self.groups,\r\n",
        "                            self.base_width, previous_dilation, norm_layer))\r\n",
        "        self.inplanes = planes * block.expansion\r\n",
        "        for _ in range(1, blocks):\r\n",
        "            layers.append(block(self.inplanes, planes, groups=self.groups,\r\n",
        "                                base_width=self.base_width, dilation=self.dilation,\r\n",
        "                                norm_layer=norm_layer))\r\n",
        "\r\n",
        "        return nn.Sequential(*layers)\r\n",
        "\r\n",
        "    def _forward_impl(self, x):\r\n",
        "        # See note [TorchScript super()]\r\n",
        "        x = self.conv1(x)\r\n",
        "        x = self.bn1(x)\r\n",
        "        x = self.relu(x)\r\n",
        "        x = self.maxpool(x)\r\n",
        "\r\n",
        "        x = self.layer1(x)\r\n",
        "        x = self.layer2(x)\r\n",
        "        x = self.layer3(x)\r\n",
        "        x = self.layer4(x)\r\n",
        "\r\n",
        "        x = self.avgpool(x)\r\n",
        "        x = torch.flatten(x, 1)\r\n",
        "        x = self.fc(x)\r\n",
        "\r\n",
        "        return x\r\n",
        "\r\n",
        "    def forward(self, x):\r\n",
        "        return self._forward_impl(x)\r\n",
        "\r\n",
        "\r\n",
        "def _resnet(arch, block, layers, pretrained, progress, **kwargs):\r\n",
        "    model = ResNet(block, layers, **kwargs)\r\n",
        "    if pretrained:\r\n",
        "        state_dict = load_state_dict_from_url(model_urls[arch],\r\n",
        "                                              progress=progress)\r\n",
        "        model.load_state_dict(state_dict)\r\n",
        "    return model\r\n",
        "\r\n",
        "def resnet18(pretrained=False, progress=True, **kwargs):\r\n",
        "    \"\"\"ResNet-18 model from\r\n",
        "    `\"Deep Residual Learning for Image Recognition\" <https://arxiv.org/pdf/1512.03385.pdf>`_\r\n",
        "\r\n",
        "    Args:\r\n",
        "        pretrained (bool): If True, returns a model pre-trained on ImageNet\r\n",
        "        progress (bool): If True, displays a progress bar of the download to stderr\r\n",
        "    \"\"\"\r\n",
        "    return _resnet('resnet18', BasicBlock, [2, 2, 2, 2], pretrained, progress,\r\n",
        "                   **kwargs)\r\n",
        "\r\n",
        "def resnext101_32x8d(pretrained=False, progress=True, **kwargs):\r\n",
        "    \"\"\"ResNeXt-101 32x8d model from\r\n",
        "    Aggregated Residual Transformation for Deep Neural Networks\" <https://arxiv.org/pdf/1611.05431.pdf>\r\n",
        "\r\n",
        "    Args:\r\n",
        "        pretrained (bool): If True, returns a model pre-trained on ImageNet\r\n",
        "        progress (bool): If True, displays a progress bar of the download to stderr\r\n",
        "    \"\"\"\r\n",
        "    kwargs['groups'] = 32\r\n",
        "    kwargs['width_per_group'] = 8\r\n",
        "    return _resnet('resnext101_32x8d', Bottleneck, [3, 4, 23, 3],\r\n",
        "                   pretrained, progress, **kwargs)"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CBec9YDepIOK",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 380
        },
        "outputId": "27a02cee-c487-4f43-fe06-4435a950e760"
      },
      "source": [
        "G =  resnet18(pretrained=False, progress=True).cuda()\r\n",
        "D = get_models()[0].cuda() \r\n",
        "D_optimizer = optim.Adam(D.parameters(), lr=.0001, betas=(0.5, 0.999))\r\n",
        "G_optimizer = optim.Adam(G.parameters(), lr=.0001, betas=(0.5, 0.999))\r\n",
        "a = torch.ones(256, 5, 32, 32).float().cuda()\r\n",
        "og = G(a)\r\n",
        "ogr = og.reshape(-1,2,1000)\r\n",
        "od = D(ogr)\r\n",
        "gtd = torch.ones(256,1).cuda()\r\n",
        "loss = nn.BCELoss()\r\n",
        "lossout = loss(od,gtd)\r\n",
        "lossout.backward()\r\n",
        "G_optimizer.step()"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-7-c3ee289db126>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mog\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mG\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mogr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mog\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mod\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mD\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mogr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0mgtd\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mones\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m256\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mBCELoss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-2-6d03d5d3c3e1>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     69\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mh0\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minit_hidden\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 71\u001b[0;31m         \u001b[0mlstm_out\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mh\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mc\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlstm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_hidden\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     72\u001b[0m         \u001b[0my\u001b[0m  \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhidden2label\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlstm_out\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m         \u001b[0;31m#self.h0 = None\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/rnn.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, hx)\u001b[0m\n\u001b[1;32m    580\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mbatch_sizes\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    581\u001b[0m             result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n\u001b[0;32m--> 582\u001b[0;31m                               self.dropout, self.training, self.bidirectional, self.batch_first)\n\u001b[0m\u001b[1;32m    583\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    584\u001b[0m             result = _VF.lstm(input, batch_sizes, hx, self._flat_weights, self.bias,\n",
            "\u001b[0;31mRuntimeError\u001b[0m: CUDA out of memory. Tried to allocate 16.72 GiB (GPU 0; 14.73 GiB total capacity; 5.24 GiB already allocated; 8.52 GiB free; 5.28 GiB reserved in total by PyTorch)"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZntMxqhCsLCG"
      },
      "source": [
        "G =  resnet18(pretrained=False, progress=True).cuda()\r\n",
        "D = get_models()[0].cuda() \r\n",
        "D_optimizer = optim.Adam(D.parameters(), lr=.0001, betas=(0.5, 0.999))\r\n",
        "G_optimizer = optim.Adam(G.parameters(), lr=.0001, betas=(0.5, 0.999))\r\n",
        "a = torch.ones(256, 5, 32, 32).float().cuda()\r\n",
        "og = generator(a)\r\n",
        "ogr = og.reshape(-1,2,1000)\r\n",
        "od = discriminator(ogr)\r\n",
        "gtd = torch.ones(256,1).cuda()\r\n",
        "loss = nn.BCELoss()\r\n",
        "lossout = loss(od,gtd)\r\n",
        "lossout.backward()\r\n",
        "D_optimizer.step()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IiyijcV4twir"
      },
      "source": [
        "x = torch.ones(256,2,200).float().cuda()\r\n",
        "out = discriminator(x).shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P6qamnAbUaHn"
      },
      "source": [
        "x = torch.ones(1,2,1000).float().cuda()\r\n",
        "discriminator.setBatchSize(batch_size = 1)\r\n",
        "print(discriminator.init_hidden()[0].shape)\r\n",
        "out = discriminator(x)\r\n",
        "print(out)\r\n",
        "print(out.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l7I1a7olacs8"
      },
      "source": [
        "x = torch.ones(1,5, 64, 64)\r\n",
        "model = resnet18()\r\n",
        "model(x).shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hkZ6tSE-kC6q"
      },
      "source": [
        "x = torch.ones(2,5, 32, 32)\r\n",
        "model = resnet18()\r\n",
        "model(x).shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "arZ9cNiClQdg"
      },
      "source": [
        "import torchvision\r\n",
        "fa = torchvision.models.resnet18(pretrained=True)\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xjOhEKIJsiMf"
      },
      "source": [
        "fa"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JaLI5JZKvLtN"
      },
      "source": [
        "fa.named_children()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RZXFRJayvOsb"
      },
      "source": [
        "fa.fc = nn.Sequential()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w1LXKUNbwZjZ"
      },
      "source": [
        "x = torch.ones(2,3, 32, 32)\r\n",
        "out = fa(x)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Oj6wr_sqwijF"
      },
      "source": [
        "out.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8GiOe-46wqcz"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}